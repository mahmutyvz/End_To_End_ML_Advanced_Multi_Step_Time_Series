{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f9a812-edfa-46af-82a9-51063c0cd445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error,mean_absolute_percentage_error,mean_squared_log_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import optuna\n",
    "from collections import Counter\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from tqdm import tqdm\n",
    "from functools import partial, reduce\n",
    "from datetime import timedelta\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4b63f6a-010b-4adf-8144-e610a0d58579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(file):\n",
    "    if file.split('.')[1]=='csv':\n",
    "        data = pd.read_csv(file)\n",
    "    elif file.split('.')[1]=='xlsx':\n",
    "        data = pd.read_excel(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bab65fd-456e-4c73-8d27-146f3ff05a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_splits(X, y, test_split,unique_len):\n",
    "    split_size = int(len(X) * (1 - test_split))  \n",
    "    while True:\n",
    "        split_size -= 1\n",
    "        if split_size % unique_len == 0:\n",
    "            break\n",
    "    X_train = X[:split_size]\n",
    "    y_train = y[:split_size]\n",
    "    X_test = X[split_size:]\n",
    "    y_test = y[split_size:]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1681855f-c56b-446d-a167-894bd04022ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_control_type(data,col):\n",
    "    if str(data[col].dtypes) not in '[ns]':\n",
    "        data[col]=pd.to_datetime(data[col])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0be6fd71-cbcc-4221-b11e-9c2decc823cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_len_control(data,col):\n",
    "    firstdateminusenddate = len(data[col])\n",
    "    len_datetime = len(data[col].unique())\n",
    "    if len_datetime == firstdateminusenddate:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d399ade8-2904-4bf0-8aa1-3ce1883f3ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_detect(df, selected_datetime):\n",
    "    df = df.sort_values(by=[selected_datetime],ascending=True)\n",
    "    unique_df_time = len(df[selected_datetime].unique())\n",
    "    df_time = len(df[selected_datetime])\n",
    "    a = int(df_time / unique_df_time)\n",
    "    unique_series_id = []\n",
    "    for col in df.columns:\n",
    "        if a == len(df[col].unique()):\n",
    "            if df[col].isnull().sum() == 0 and df[selected_datetime].isnull().sum() == 0:\n",
    "                df[\"concated\"] = df[col].astype(str) + df[selected_datetime].astype(str)\n",
    "                if df_time == len(df[\"concated\"].unique()):\n",
    "                    unique_series_id.append(col)\n",
    "    return unique_series_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "784e330e-4e54-40fb-9654-8b1ef817fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_sort(data,col,col2):\n",
    "    data = data.sort_values(by=[col,col2],ascending=[True,True]).reset_index(drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f070040-3a2c-4f96-aa80-ee56fdff4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_column_info_pxexpress(data,num_cols,timestamp_column,unique_col):\n",
    "    fig = make_subplots(rows=len(num_cols), cols=1, subplot_titles=num_cols)\n",
    "    print(\"Store : \",unique_col)\n",
    "    for i, col in enumerate(num_cols):\n",
    "        line_chart = px.line(data, x=timestamp_column, y=col)\n",
    "        line = line_chart.data[0]\n",
    "        fig.add_trace(line, row=i + 1, col=1)\n",
    "    num_rows = data.shape[1]\n",
    "    fig.update_xaxes(title_text='Date', row=num_cols, col=1)\n",
    "    fig.update_layout(showlegend=False, height=150*num_rows, width=1400)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f4a7a29-14e8-481b-89ac-d94322f0b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_column_info_pyplot(data, num_cols, timestamp_column, unique_col):\n",
    "    fig, axes = plt.subplots(len(num_cols), 1, figsize=(14, 4*len(num_cols)))\n",
    "    plt.suptitle(f\"Store: {unique_col}\")\n",
    "\n",
    "    for i, col in enumerate(num_cols):\n",
    "        axes[i].plot(data[timestamp_column], data[col])\n",
    "        axes[i].set_title(col)\n",
    "        axes[i].set_xlabel(\"Date\")\n",
    "        axes[i].set_ylabel(col)\n",
    "    plt.subplots_adjust(hspace=0.4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffca4538-fc65-4fe9-a17c-9ee0b5487cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_engineering(data,col):\n",
    "    data['Day'] = data[col].dt.day.astype(str)\n",
    "    data['Month'] = data[col].dt.month.astype(str)\n",
    "    data['Year'] = data[col].dt.year.astype(str)         \n",
    "    data['DayOfWeek'] = data[col].dt.dayofweek.astype(str)\n",
    "    data['DayOfYear'] = data[col].dt.dayofyear.astype(str)\n",
    "    data['WeekOfYear'] = data[col].dt.weekofyear.astype(str)\n",
    "    data['Quarter'] = data[col].dt.quarter.astype(str)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce497aaa-83cc-429e-9cbe-1b01ad9827d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_detect(data, selected_datetime):\n",
    "    dates = data[selected_datetime].unique()\n",
    "    frequencies = [int(int((dates[x + 1] - dates[x])) / (1000000000)) for x in range(0, len(dates) - 1)]\n",
    "    time_type = ''\n",
    "    frequency = list(Counter(frequencies).most_common(1)[0])[0]\n",
    "    if frequency >= 31536000:\n",
    "        time_type = 'years' if frequency % 31536000 == 0 else 'quarters'\n",
    "    elif frequency >= 7948800:\n",
    "        time_type = 'quarters' if frequency % 7948800 == 0 else 'months'\n",
    "    elif frequency >= 2592000:\n",
    "        time_type = 'months' if frequency % 2592000 == 0 else 'weeks'\n",
    "    elif frequency >= 604800:\n",
    "        time_type = 'weeks' if frequency % 604800 == 0 else 'days'\n",
    "    elif frequency >= 86400:\n",
    "        time_type = 'days' if frequency % 86400 == 0 else 'hours'\n",
    "    elif frequency >= 3600:\n",
    "        time_type = 'hours' if frequency % 3600 == 0 else 'minutes'\n",
    "    elif frequency >= 60:\n",
    "        time_type = 'minutes' if frequency % 60 == 0 else 'seconds'\n",
    "    elif frequency >= 1:\n",
    "        time_type = 'seconds'\n",
    "    return time_type,frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7530cd3c-08e7-4d99-b271-355bbdd8dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADF_Test(data, target, selected_datetime_feature, SignificanceLevel=.05):\n",
    "    data = data.set_index(\n",
    "        pd.DatetimeIndex(data[selected_datetime_feature]))\n",
    "    data = data.drop([selected_datetime_feature], axis=1)\n",
    "    data = data[[target]]\n",
    "    adfTest = adfuller(data, autolag='AIC')\n",
    "\n",
    "    pValue = adfTest[1]\n",
    "\n",
    "    if (pValue < SignificanceLevel):\n",
    "        isStationary_adf = True\n",
    "    else:\n",
    "        isStationary_adf = False\n",
    "\n",
    "    dataResults = pd.Series(adfTest[0:4],\n",
    "                           index=['Adata Test Statistic', 'P-Value', '# Lags Used', '# Observations Used'])\n",
    "    \n",
    "    # Add Critical Values\n",
    "    for key, value in adfTest[4].items():\n",
    "         dataResults['Critical Value (%s)' % key] = value\n",
    "    \n",
    "    print('Augmented Dickey-Fuller Test Results:')\n",
    "    print(dataResults)\n",
    "    print(isStationary_adf)\n",
    "    return isStationary_adf\n",
    "    \n",
    "def KPSS_Test(data, target, selected_datetime_feature, trend,SignificanceLevel=.05):\n",
    "    \"\"\"\n",
    "    Regression: This parameter determines the type of regression to be used in calculating the test statistic. The KPSS test applies a regression model to examine the stationarity property of the data. \n",
    "    In this model, a component of the data is predicted, and the test statistic is calculated based on the remaining residuals. \"c\" (constant): This option represents a regression model with a constant component.\n",
    "    The test examines the stationarity property of the series with this component. \"ct\" (constant and trend): This option represents a regression model that includes both a constant component and a linear trend component.\n",
    "    The test assesses the stationarity property of the series with these two components. The nlags parameter specifies the number of lags used in the KPSS test. \n",
    "    This parameter determines how many steps back the regression model used in calculating the test statistic looks. The number of lags is a method used to examine the stationarity property of the series.\n",
    "    If nlags is set to 25, the regression model will be designed to look back 25 steps (25 observations) when calculating the test statistic.\n",
    "    This means that the test will use the last 25 observations when evaluating the stationarity property of the series.\n",
    "    \"\"\"\n",
    "    data = data.set_index(\n",
    "        pd.DatetimeIndex(data[selected_datetime_feature]))\n",
    "    data = data.drop([selected_datetime_feature], axis=1)\n",
    "    data = data[[target]]\n",
    "    kpsstest = kpss(data, regression='ct',nlags=trend)\n",
    "    kpss_output = pd.Series(kpsstest[0:3], index=['Test Statistic', 'p-value', '#Lags Used'])\n",
    "    for key, value in kpsstest[3].items():\n",
    "         kpss_output['Critical Value (%s)' % key] = value\n",
    "    print(kpss_output)\n",
    "    pValue = kpsstest[1]\n",
    "    if (pValue < SignificanceLevel):\n",
    "        isStationary_kpss = False\n",
    "    else:\n",
    "        isStationary_kpss = True\n",
    "    print(isStationary_kpss)\n",
    "    return isStationary_kpss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d8381ba-5a05-4091-a1a1-5e1f2b52af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def editing_index(data, col, col2):\n",
    "    data = data.set_index([col, col2]).sort_index()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9a7cbab-710f-4cd7-a988-d940037d9f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derived_lag_features(data, lag_features, lag_bound=5):\n",
    "    for col in lag_features:\n",
    "        for lag in range(1, int(lag_bound) + 1):\n",
    "            f_name = f'{col}_lag_{lag}'\n",
    "            data[f_name] = data[col].shift(int(lag))\n",
    "    return data.loc[:, data.columns.str.contains('_lag_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cce43081-8f4f-48d0-bfd9-c249185d7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def app_lag_data(data, WINDOW, derived_lag_features_cols,series_id,datetime_feature):\n",
    "    data_1 = data.copy()\n",
    "    data_2 = []\n",
    "    data_1 = data_1.reset_index()\n",
    "    for seri in data_1[series_id].unique():\n",
    "        v = int(WINDOW) + 1\n",
    "        data_3 = pd.DataFrame()\n",
    "        data_4 = data_1[data_1[series_id] == seri]\n",
    "        data_4 = editing_index(data_4, datetime_feature,series_id)\n",
    "        if v < 7:\n",
    "            for i in tqdm(range(len(data_4) - int(WINDOW))):\n",
    "                data_5 = derived_lag_features(data_4[v - int(WINDOW):v + 1], derived_lag_features_cols,\n",
    "                                                 lag_bound=WINDOW).dropna()\n",
    "                v += 1\n",
    "                data_3 = data_3.append(data_5)\n",
    "            data_2.append(data_3)\n",
    "        else:\n",
    "            for i in tqdm(range(len(data_4) - int(WINDOW))):\n",
    "                data_5 = derived_lag_features(data_4[v - int(WINDOW):v][-6:],\n",
    "                                                 derived_lag_features_cols).dropna()\n",
    "                v += 1\n",
    "                data_3 = data_3.append(data_5)\n",
    "            data_2.append(data_3)\n",
    "    lagged_data = pd.concat(data_2)\n",
    "    lagged_data = lagged_data.sort_index()\n",
    "    return lagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "742c02bf-c3d4-4802-abbe-7bcd627bc01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_type_detect(time_type):\n",
    "        if time_type == 'years':\n",
    "            time_num = 31536000\n",
    "        elif time_type == 'quarters':\n",
    "            time_num = 7948800\n",
    "        elif time_type == 'months':\n",
    "            time_num = 2592000\n",
    "        elif time_type == 'weeks':\n",
    "            time_num = 604800\n",
    "        elif time_type == 'days':\n",
    "            time_num = 86400\n",
    "        elif time_type == 'hours':\n",
    "            time_num = 3600\n",
    "        elif time_type == 'minutes':\n",
    "            time_num = 60\n",
    "        elif time_type == 'seconds':\n",
    "            time_num = 1\n",
    "        return time_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1fb3e8f-f928-468c-87ea-f01d1d248d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_features(data, derivation_lagged_cols, win, window_list,time_type, frequency):\n",
    "    functions = {\n",
    "        'min': lambda x: x.rolling(window=win, min_periods=1).min(),\n",
    "        'max': lambda x: x.rolling(window=win, min_periods=1).max(),\n",
    "        'mean': lambda x: x.rolling(window=win, min_periods=1).mean(),\n",
    "        'std': lambda x: x.rolling(window=win, min_periods=1).std(),\n",
    "        'median': lambda x: x.rolling(window=win, min_periods=1).median()\n",
    "    }\n",
    "    time_num = time_type_detect(time_type)\n",
    "    for win in window_list:\n",
    "        for function_name, function in functions.items():\n",
    "            for j in derivation_lagged_cols:\n",
    "                data[f'{j}_stat_{function_name}_{int(win * frequency / time_num)}_{time_type}'] = data[[j]].apply(function)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10a219d7-fb12-4bfb-b788-ec07474f3995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def app_derived_data(data, derived_lag_features_cols, WINDOW, window_list,time_type, frequency,series_id,datetime_feature):\n",
    "    data_1 = data.copy()\n",
    "    data_1 = data_1.reset_index()\n",
    "    derives = []\n",
    "    for seri in data_1[series_id].unique():\n",
    "        v = int(WINDOW) + 1\n",
    "        data_2 = pd.DataFrame()\n",
    "        data_3 = data_1[data_1[series_id] == seri]\n",
    "        data_3 = editing_index(data_3, datetime_feature, series_id)\n",
    "        if v < 7:\n",
    "            for i in tqdm(range(len(data_3) - int(WINDOW))):\n",
    "                data_4 = derive_features(data_3[v - int(WINDOW):v + 1], derived_lag_features_cols, WINDOW,window_list,time_type,frequency).iloc[\n",
    "                    -1].to_frame().T\n",
    "                v += 1\n",
    "                data_2 = data_2.append(data_4)\n",
    "            derives.append(data_2)\n",
    "        else:\n",
    "            for i in tqdm(range(len(data_3) - int(WINDOW))):\n",
    "                data_4 = derive_features(data_3[v - int(WINDOW):v], derived_lag_features_cols, WINDOW,window_list,time_type,frequency).iloc[\n",
    "                    -1].to_frame().T\n",
    "                v += 1\n",
    "                data_2 = data_2.append(data_4)\n",
    "            derives.append(data_2)\n",
    "    derived_data = pd.concat(derives)\n",
    "    derived_data = derived_data.loc[:, derived_data.columns.str.contains('stat_')]\n",
    "    derived_data = derived_data.astype('float32')\n",
    "    derived_data = derived_data.sort_index()\n",
    "    return derived_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b846589b-09fb-4bc9-b421-49da317bd1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def app_diff_data(df, window, lagged_data, derived_data, target, time_type):\n",
    "    data = df.copy()\n",
    "    lag_data_target_columns = [x for x in lagged_data.columns if target in x]\n",
    "    derived_diff_inp_column = derived_data[f'{target}_stat_mean_{window}_{time_type}']\n",
    "    derived_data_target_columns = [x for x in derived_data.columns if target in x and derived_diff_inp_column.name not in x]\n",
    "    for i in lag_data_target_columns:\n",
    "        data[f'{target}_diff_{i.replace(target + \"_\", \"\", 1)}'] = data[target] - lagged_data[i]\n",
    "        data[f'{target}_{i.replace(target + \"_\", \"\", 1)}_diff_{derived_diff_inp_column.name}'] = lagged_data[\n",
    "                                                                                                     i] - derived_diff_inp_column\n",
    "    for k in derived_data_target_columns:\n",
    "        data[f'{target}_diff_{k.replace(target + \"_\", \"\", 1)}'] = data[target] - derived_data[k]\n",
    "        data[f'{target}_{k.replace(target + \"_\", \"\", 1)}_diff_{derived_diff_inp_column.name}'] = derived_data[\n",
    "                                                                                                     k] - derived_diff_inp_column\n",
    "    data = data.loc[:, data.columns.str.contains('diff')]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17df7cff-b468-4d55-acb8-f3f65cd0b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(data, lagged_data, derived_data, diff_data=None):\n",
    "    list_of_datas = [data, lagged_data, derived_data]\n",
    "    if diff_data:\n",
    "        list_of_datas.append(diff_data)\n",
    "    merge = partial(pd.merge, left_index=True, right_index=True)\n",
    "    final_data = reduce(merge, list_of_datas)\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1089c68-f4e0-43bc-938f-5e16eef726ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trend_removal_log(data,target_list):\n",
    "    negative_values = []\n",
    "    [[negative_values.append({column: x}) for x in range(len(data)) if data[column][x] < 0] for index, column in enumerate(data[target_list])]\n",
    "    data[target_list] = abs(data[target_list])\n",
    "    data[target_list] = np.log1p(data[target_list])\n",
    "    if not negative_values:\n",
    "        [data.rename({x: f\"{x}_log\"}, axis=1, inplace=True) for x in data[target_list].columns.tolist()]\n",
    "        return data\n",
    "    for i in negative_values:\n",
    "        for key, value in i.items():\n",
    "            data[key][value] = data[key][value] * int(-1)\n",
    "    [data.rename({x: f\"{x}_log\"}, axis=1, inplace=True) for x in data[target_list].columns.tolist()]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbc64e66-1f87-4e01-afcb-3d7c8ff6d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df,target,horizon,len_unique):\n",
    "    X = df.drop([target], axis=1)\n",
    "    y = df[[target]]\n",
    "    horizon = int(horizon)\n",
    "    y = derived_lag_features(y, [target], horizon).dropna()\n",
    "    X = X.iloc[horizon*len_unique:]\n",
    "    y = y.iloc[horizon*len_unique - horizon:]\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b7006f4-a250-4a56-9bbd-e1c3c6627aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fold(X,fold_number,unique_len):\n",
    "    X = X.reset_index()\n",
    "    index = int(len(X)/(fold_number+1))\n",
    "    while index % unique_len != 0:\n",
    "        index -= 1\n",
    "    cv_partitions = []\n",
    "    for i in range(1,fold_number+1):\n",
    "        train_index = X.iloc[:index*i]\n",
    "        if i == fold_number:\n",
    "            val_index = X.iloc[index*i:]\n",
    "        else:\n",
    "            val_index = X.iloc[index*i:index*(i+1)]\n",
    "        cv_partitions.append({f'train': train_index.index.tolist(),\n",
    "                              f'validation': val_index.index.tolist()})\n",
    "    return cv_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc498f71-b5a3-4c23-a3c4-143f4965b53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_build(alg,num_cols,cat_cols):\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median', fill_value='missing')),\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_cols),\n",
    "            ('cat', categorical_transformer, cat_cols)], remainder='passthrough')\n",
    "\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('algorithm', MultiOutputRegressor(alg))])\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50be1b18-f2d8-4897-b3cf-9a8238e4f031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial,X,y,fold_list,alg,num_cols,cat_cols):   \n",
    "    params = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate',0.05, 0.5,step=0.01),\n",
    "        'n_estimators': trial.suggest_int('n_estimators',10, 3000,step=10),\n",
    "        'max_bin': trial.suggest_int('max_bin',16, 2048,step=16),\n",
    "        'subsample': trial.suggest_float('subsample', 0.1, 1,step=0.1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 6, 10,step=1),\n",
    "    }\n",
    "    liste = []  \n",
    "    for i in range(len(fold_list)):\n",
    "        train_indices = fold_list[i]['train']\n",
    "        val_indices = fold_list[i]['validation']\n",
    "        X_train = X.iloc[train_indices]\n",
    "        y_train = y.iloc[train_indices]\n",
    "        X_val = X.iloc[val_indices]                    \n",
    "        y_val = y.iloc[val_indices]\n",
    "        alg.set_params(**params)\n",
    "        pipe = pipeline_build(alg,num_cols,cat_cols)\n",
    "        pipe.fit(X_train,y_train)\n",
    "        y_pred = pipe.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        liste.append(rmse)\n",
    "    print(f'RMSE : {np.mean(liste)}')\n",
    "    return np.mean(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3ffffb4-28b0-4787-8ee3-24bd8a8943ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_calculate(y_val,y_pred,X_train):\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    rmsle = mean_squared_log_error(y_val, y_pred),\n",
    "    r2 = r2_score(y_val, y_pred),\n",
    "    adj_r2 = 1 - (1 - (r2_score(y_val, y_pred))) * (X_train.shape[0] - 1) / (X_train.shape[0] - len(X_train.columns.tolist()) - 1)\n",
    "    mape = mean_absolute_percentage_error(y_val, y_pred)\n",
    "    scores = {'RMSE' : rmse,'MAE' : mae,'RMSLE' : rmsle,'R-Squared' : r2,\n",
    "                  'Adj R-Squared' : adj_r2,'MAPE' : mape}\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e27febe-9feb-43d4-970a-1c7acf2b872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_visualize_pxexpress(y_val_,y_pred_,target,unique_col,m,i):\n",
    "    for k in range(len(y_val_.columns.tolist())):\n",
    "        fig = go.Figure()\n",
    "        y_val_vis = y_val_.iloc[:,k]\n",
    "        y_pred_vis = y_pred_.iloc[:,k]\n",
    "        real_table_name = f'{target} and {unique_col} : {m} Week : {k+1}'\n",
    "        fig.add_trace(go.Scatter(x=y_val_.index, y=y_val_vis, mode='lines',name=f'Real Day {real_table_name}',line_color='#247AFD'))\n",
    "        fig.add_trace(go.Scatter(x=y_val_.index, y=y_pred_vis, mode='lines',name=f'Pred Day {real_table_name}',line_color='#ff0000'))\n",
    "        fig.update_layout(title=f'Test Değerleri ve Tahminler Fold {i + 1}',\n",
    "                  xaxis_title='Time',\n",
    "                  yaxis_title='Horizon Time Steps')\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b199ef77-b8b5-49ab-b486-83ddcb93550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_visualize_plotly(y_val_, y_pred_, target, unique_col, m, i):\n",
    "    for k in range(len(y_val_.columns.tolist())):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        y_val_vis = y_val_.iloc[:, k]\n",
    "        y_pred_vis = y_pred_.iloc[:, k]\n",
    "        \n",
    "        real_table_name = f'{target} and {unique_col} : {m} Week : {k + 1}'\n",
    "\n",
    "        plt.plot(y_val_.index, y_val_vis, label=f'Real Day {real_table_name}', color='#247AFD')\n",
    "        plt.plot(y_val_.index, y_pred_vis, label=f'Pred Day {real_table_name}', color='#ff0000')\n",
    "\n",
    "        plt.title(f'Test Values And Predictions Fold {i + 1}')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Horizon Time Steps')\n",
    "        plt.legend()    \n",
    "        plt.subplots_adjust(hspace=0.4)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5147663c-0f3e-406a-a09c-09057321ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_visualization(X,y,fold_list,horizon,num_cols,cat_cols,alg,timestamp_column,unique_col,target):\n",
    "    for i in range(len(fold_list)):\n",
    "        train_indices = fold_list[i]['train']\n",
    "        val_indices = fold_list[i]['validation']\n",
    "        X_train = X.iloc[train_indices]\n",
    "        y_train = y.iloc[train_indices]\n",
    "        X_val = X.iloc[val_indices]                    \n",
    "        y_val = y.iloc[val_indices]  \n",
    "        pipe = pipeline_build(alg,num_cols,cat_cols)\n",
    "        pipe.fit(X_train,y_train)\n",
    "        y_pred = pipe.predict(X_val)\n",
    "        scores = metrics_calculate(y_val,y_pred,X_train)\n",
    "        print(f\"Fold {i + 1} Scores : {scores}\")\n",
    "        model_preds_columns_list = [[f'+{i + 1}_Horizon_time_step'][0] for i in range(horizon)]\n",
    "        y_pred = pd.DataFrame(y_pred, index=X_val.index,\n",
    "                                  columns=[model_preds_columns_list])\n",
    "        y_pred = y_pred.sort_values(by=[unique_col,timestamp_column],ascending=[True,True])\n",
    "        y_pred = y_pred.reset_index()\n",
    "        y_val = y_val.reset_index()\n",
    "        print(f\"Train Start-End: {X_train.index[0]} - {X_train.index[-1]}\")\n",
    "        print(f\"Validation Start-End: {X_val.index[0]} - {X_val.index[-1]}\")\n",
    "        indice = 0\n",
    "        indice_ = len(y_pred[timestamp_column])/len(y_val[unique_col].unique())\n",
    "        indice_end = len(y_pred[timestamp_column])/len(y_val[unique_col].unique())\n",
    "        for m in y_val[unique_col].unique():\n",
    "            y_val_ = y_val[y_val[unique_col] == m]\n",
    "            y_pred_ = y_pred.iloc[int(indice):int(indice_)]\n",
    "            y_val_=y_val_.set_index(timestamp_column)\n",
    "            y_val_.drop(unique_col,axis=1,inplace=True)\n",
    "            y_pred_.drop(unique_col,axis=1,inplace=True)\n",
    "            y_pred_.drop(timestamp_column,axis=1,inplace=True)\n",
    "            # If you want to plot real and predicted data using Plotly Express, you can use the code below with comments disabled.\n",
    "            #pred_visualize_pxexpress(y_val_,y_pred_,target,unique_col,m,i)\n",
    "            pred_visualize_plotly(y_val_,y_pred_,target,unique_col,m,i)\n",
    "            indice += indice_end\n",
    "            indice_ += indice_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71ee9bbe-8a1f-40cd-899c-71748506885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = read_dataset(\"C:/Users/MahmutYAVUZ/Desktop/Software/Python/kaggle/advanced_multiple_time_series/data/raw/Walmart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be9868-d9f4-40c8-b41c-f21b11bb1e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aead2487-a374-492b-9472-ff566ef3c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96c74a-af9d-4d83-8973-db78fa1d6810",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_column = 'Date'\n",
    "target = 'Weekly_Sales' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35373c1-1c2c-49fc-bfc8-5f73bde5f6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=time_control_type(train,timestamp_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65c562-e3d3-477a-935c-a906fc923932",
   "metadata": {},
   "outputs": [],
   "source": [
    "control = time_len_control(train,timestamp_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1572e71-8a7f-4e94-9c66-63cc9686b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if control:\n",
    "    unique_list = auto_detect(train,timestamp_column)\n",
    "    print(unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ac49b-f7c1-48c6-ab2b-496be66fa489",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = date_sort(train,timestamp_column,unique_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d717e-41a4-4f8a-bfac-449b3c05951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb17d8-6f37-45b0-9d2a-2fe617ed67e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train[unique_list[0]].unique():\n",
    "    data = train[train[unique_list[0]] == i]\n",
    "    num_cols = data.select_dtypes(include=['float','int']).columns.tolist()\n",
    "    num_cols.remove(unique_list[0])\n",
    "    #If you want to use Plotly Express, please use the date_column_info_pyexpress function\n",
    "    #date_column_info_pxexpress(data,num_cols,timestamp_column,i)\n",
    "    date_column_info_pyplot(data,num_cols,timestamp_column,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa8963-7aed-4b1d-83e3-ddea59ba125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = date_engineering(train,timestamp_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e58e468-a157-4b73-8110-77bec3b25d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_type,frequency = frequency_detect(train,timestamp_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed734991-f0de-4028-8723-37ad13a4c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53df522-c643-4374-b4e9-9262a303f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "isStationary_adf = ADF_Test(train,target,timestamp_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0698d0e8-a949-47de-a872-bf2adbb0414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "isStationary_kpss = KPSS_Test(train,target,timestamp_column,trend=315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd26002-76ea-4b72-927f-63e37a94f5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ac96ea-948a-466d-b037-7bb82f447de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3c5f4b-bb68-402e-a6a2-5b11eda08367",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = editing_index(train,timestamp_column,unique_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c094b7-9e4f-4de6-875d-0f88d5cd4944",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43fb0f8-22d8-4895-b5cc-517d70c0825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = train.select_dtypes(include=['float','int']).columns.tolist() \n",
    "cat_cols = train.select_dtypes(exclude=['float','int']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ff7161-716a-4306-ba6f-56db14cb27b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols.remove('Holiday_Flag')\n",
    "cat_cols.append('Holiday_Flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed4a08-7bb4-49a8-9d45-7f3700abe7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols,cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb4da32-ef99-465f-b005-57f5f4a2f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_data = app_lag_data(train,window,num_cols,unique_list[0],timestamp_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e1ec0-5c42-4cbb-993f-6c96fa1e626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38728a65-7add-41f2-9721-b44bf47f7ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_list = [50,25,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c1f4fb-f0c4-4ce7-a1ce-ce26104da813",
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_data = app_derived_data(train,num_cols,window,window_list,time_type,frequency,unique_list[0],timestamp_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a857f8e1-6e89-46d9-b0f1-ca73d2290aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_data = derived_data.reset_index()\n",
    "derived_data.rename(columns = {'level_0':timestamp_column,'level_1':unique_list[0]},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe2b224-4a23-4f53-8eb8-6c15e76c1495",
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_data = editing_index(derived_data,timestamp_column,unique_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a6e172-2869-466e-9ba2-20901ea54b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data,window,unique_len):\n",
    "    if int(window) < int(6):\n",
    "        data = data.iloc[(int(window) * int(unique_len)) + int(unique_len):]\n",
    "        data = data.sort_index()\n",
    "    else:\n",
    "        data = data.iloc[int(window) * int(unique_len):]\n",
    "        data = data.sort_index()\n",
    "    return datadef split_data(data,window,unique_len):\n",
    "    if int(window) < int(6):\n",
    "        data = data.iloc[(int(window) * int(unique_len)) + int(unique_len):]\n",
    "        data = data.sort_index()\n",
    "    else:\n",
    "        data = data.iloc[int(window) * int(unique_len):]\n",
    "        data = data.sort_index()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a5816-9809-4a4f-bfa0-7d953566c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = split_data(train,window,len(train.reset_index()[unique_list[0]].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fed7b6-9e62-4720-a346-072912c31423",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isStationary_kpss:\n",
    "    diff_data = app_diff_data(train,window,lagged_data,derived_data,target,time_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495d752f-48e8-4a2e-b726-4b32245e20df",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = merge_data(train,lagged_data,derived_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3590d620-5c27-46ad-b7e1-63db3dd0be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b6b27-7546-419e-a407-3018759ff7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isStationary_adf:\n",
    "    target_list = [x for x in final_data.columns.tolist() if x.startswith(target) and x != target]\n",
    "    final_data = trend_removal_log(final_data,target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a52484-347a-4c1c-a508-1443749a47ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a899b42-4965-4cab-9684-eed46bcc6e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 4\n",
    "X,y = split(final_data,target,horizon,len(train.reset_index()[unique_list[0]].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f92e0c9-ea0a-4e3a-8565-91e56f05ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4621b8-1aeb-40d8-8c9e-b9968d9f6028",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d82b83f-b768-476d-912b-00b4c3b4e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = make_train_test_splits(X,y,0.20,len(train.reset_index()[unique_list[0]].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7784bf72-234d-465d-8546-1fa0ce097598",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_list = get_fold(X_train,3,len(train.reset_index()[unique_list[0]].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6bd4e6-d977-4c87-9adc-db9e5fb7091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = X.select_dtypes(include=['float','int']).columns.tolist() \n",
    "cat_cols = X.select_dtypes(exclude=['float','int']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e629ff6-f073-414e-92db-3bfa94a1dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols.remove('Holiday_Flag')\n",
    "cat_cols.append('Holiday_Flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63765997-3acf-43d7-9e1d-7a6dcf6e92d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c952cb4e-f43f-4911-a738-a1df0604439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15243241-81e1-489d-96d4-ab0730522ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90085f0-3f05-4e37-8e8e-aa66791f6912",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a268750-1a3d-4be2-b78d-428906ed7422",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_list = [XGBRegressor(random_state=42),LGBMRegressor(random_state=42,verbose=-1),CatBoostRegressor(random_state=42,verbose=0)]\n",
    "rmse_list = []\n",
    "for alg in alg_list:\n",
    "    for i in range(len(fold_list)):\n",
    "        train_indices = fold_list[i]['train']\n",
    "        val_indices = fold_list[i]['validation']\n",
    "        X_train_2 = X_train.iloc[train_indices]\n",
    "        y_train_2 = y_train.iloc[train_indices]\n",
    "        X_val = X_train.iloc[val_indices]                    \n",
    "        y_val = y_train.iloc[val_indices]\n",
    "        pipe = pipeline_build(alg,num_cols,cat_cols)\n",
    "        pipe.fit(X_train_2,y_train_2)\n",
    "        y_pred = pipe.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, pipe.predict(X_val)))\n",
    "        rmse_list.append(rmse)\n",
    "    print(f'RMSE And {type(alg).__name__} : {np.mean(rmse_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d23bc-2171-4651-907c-e10e8872b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction = 'minimize',study_name = 'advanced_multiple_time_series')\n",
    "study.optimize(lambda trial: objective(trial,X,y,fold_list,LGBMRegressor(random_state=42,verbose=-1),num_cols,cat_cols), n_trials = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef491ed-0677-4417-aa00-cfb3fbc8ab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Value:', study.best_value)\n",
    "print('Best Params:', study.best_params)\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086076d7-7795-45ca-a3da-c146e6845f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_distance = time_type_detect(time_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd28670c-7d9f-4e43-a117-53fe121b3470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8095e893-b6e2-4ae9-b789-6ee4460e75cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f0efd-878e-4fd8-bfbe-67ec97cd4b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg = CatBoostRegressor(random_state=42,verbose=0)\n",
    "train_and_visualization(X,y,fold_list,horizon,num_cols,cat_cols,alg,timestamp_column,unique_list[0],target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
